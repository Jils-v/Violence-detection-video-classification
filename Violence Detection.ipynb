{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ef91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, LSTM, Reshape, TimeDistributed, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d43e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_data_generator(directory, batch_size):\n",
    "    target_size = (240, 240)\n",
    "    class_names = sorted(os.listdir(directory))\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    while True:\n",
    "        video_frames = []\n",
    "        labels = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        for class_index, class_name in enumerate(class_names):\n",
    "            class_dir = os.path.join(directory, class_name)\n",
    "            for video_name in os.listdir(class_dir):\n",
    "                video_path = os.path.join(class_dir, video_name)\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                \n",
    "                frames = []\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    cropped_frame = cv2.resize(frame, target_size)\n",
    "                    frames.append(cropped_frame)\n",
    "                \n",
    "                cap.release()\n",
    "                if len(frames) > 0:\n",
    "                    video_frames.append(frames)\n",
    "                    labels.append(class_index)\n",
    "                \n",
    "                if len(video_frames) == batch_size:\n",
    "                    video_frames = np.array(video_frames)\n",
    "                    video_frames = video_frames / 255.0\n",
    "                    video_frames = np.reshape(video_frames, (1, -1, 240, 240, 3))\n",
    "                    labels = tf.keras.utils.to_categorical(labels, num_classes, dtype=float)\n",
    "                    yield video_frames, labels\n",
    "                    video_frames = []\n",
    "                    labels = []\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    if batch_count == batch_size:\n",
    "                        batch_count = 0\n",
    "        \n",
    "        if len(video_frames) > 0:\n",
    "            l = len(video_frames)\n",
    "            video_frames = np.array(video_frames)\n",
    "            video_frames = video_frames / 255.0\n",
    "            video_frames = np.reshape(video_frames, (1, -1, 240, 240, 3))\n",
    "            labels = tf.keras.utils.to_categorical(labels, num_classes, dtype=float)\n",
    "            yield video_frames, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac90940",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = video_data_generator(\"NewData/train\", 1)\n",
    "validation_generator = video_data_generator(\"NewData/validation\", 1)\n",
    "\n",
    "# video_frames, labels = next(train_generator)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ecd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "steps_per_epoch = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87005242",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(None,240,240,3)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80042682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "# model.add(LSTM(32, dropout=0.2, return_sequences=True, input_shape=(None, 240*240*3)))\n",
    "# model.add(LSTM(64))\n",
    "# # model.add(Flatten())\n",
    "# model.add(Dense(512, activation='softmax'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1eda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10730283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5118d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"model-train-{epoch:01d}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('model-train-30.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55111bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs=30, validation_data=validation_generator,validation_steps=200, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ecf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17069c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = video_data_generator(\"NewData/test\", 1)\n",
    "model.evaluate(test_generator, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frames(frames_original):\n",
    "    frames = []\n",
    "    target_size = (240, 240)\n",
    "    for frame in frames_original:\n",
    "        if np.any(frame != 0):\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            _, threshold = cv2.threshold(gray_frame, 1, 255, cv2.THRESH_BINARY)\n",
    "            contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            if len(contours) > 0:\n",
    "                x, y, w, h = cv2.boundingRect(contours[0])\n",
    "                cropped_frame = frame[y:y+h, x:x+w, :]\n",
    "                cropped_frame = cv2.resize(cropped_frame, target_size)\n",
    "                frames.append(cropped_frame)\n",
    "                \n",
    "    frames = np.array(frames)\n",
    "    frames = torch.tensor(frames, dtype=torch.float32)\n",
    "    frames = frames / 255.0\n",
    "    frames = np.reshape(frames, (-1, 240*240*3))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e767792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = 'data/test/Fight/6.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frames = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "preprocessed_frames = preprocess_frames(frames)\n",
    "preprocessed_frames = preprocessed_frames.reshape((1, -1, 240*240*3))\n",
    "preprocessed_frames = tf.convert_to_tensor(preprocessed_frames, dtype=tf.float32) \n",
    "\n",
    "predictions = model.predict(preprocessed_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a26ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
